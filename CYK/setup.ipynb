{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7fbf1cc-43ac-4d12-9ebf-c6bd0f96636f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859850df-dcff-4059-b693-6b6f986a366c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP I) (VP (V saw) (NP (Det a) (N dog))))\n",
      "         S             \n",
      "  _______|___           \n",
      " |           VP        \n",
      " |    _______|___       \n",
      " |   |           NP    \n",
      " |   |        ___|___   \n",
      " NP  V      Det      N \n",
      " |   |       |       |  \n",
      " I  saw      a      dog\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m           CFG\n",
       "\u001b[1;31mString form:\u001b[0m   \n",
       "Grammar with 12 productions (start state = S)\n",
       "           S -> NP VP\n",
       "           NP -> Det N\n",
       "           NP -> 'I'\n",
       "           VP <...> n'\n",
       "           Det -> 'the'\n",
       "           N -> 'dog'\n",
       "           N -> 'cat'\n",
       "           N -> 'bat'\n",
       "           V -> 'chased'\n",
       "           V -> 'saw'\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\nltk\\grammar.py\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "A context-free grammar.  A grammar consists of a start state and\n",
       "a set of productions.  The set of terminals and nonterminals is\n",
       "implicitly specified by the productions.\n",
       "\n",
       "If you need efficient key-based access to productions, you\n",
       "can use a subclass to implement it.\n",
       "\u001b[1;31mInit docstring:\u001b[0m\n",
       "Create a new context-free grammar, from the given start state\n",
       "and set of ``Production`` instances.\n",
       "\n",
       ":param start: The start symbol\n",
       ":type start: Nonterminal\n",
       ":param productions: The list of productions that defines the grammar\n",
       ":type productions: list(Production)\n",
       ":param calculate_leftcorners: False if we don't want to calculate the\n",
       "    leftcorner relation. In that case, some optimized chart parsers won't work.\n",
       ":type calculate_leftcorners: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define a context-free grammar\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det N | 'I'\n",
    "    VP -> V NP\n",
    "    Det -> 'a' | 'an' | 'the'\n",
    "    N -> 'dog' | 'cat' | 'bat'\n",
    "    V -> 'chased' | 'saw'\n",
    "\"\"\")\n",
    "\n",
    "# Create a parser based on the defined CFG\n",
    "parser = nltk.ChartParser(grammar)\n",
    "\n",
    "# Define a sentence to parse\n",
    "sentence = \"I saw a dog\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = sentence.split()\n",
    "\n",
    "# Parse the sentence and print the parse trees\n",
    "for tree in parser.parse(tokens):\n",
    "    print(tree)\n",
    "    tree.pretty_print()\n",
    "grammar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9585f4-c6ee-4940-b359-7809d55b3932",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'WeightedProduction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m production \u001b[38;5;129;01min\u001b[39;00m productions:\n\u001b[0;32m     18\u001b[0m         rhs, prob \u001b[38;5;241m=\u001b[39m production\n\u001b[1;32m---> 19\u001b[0m         grammar_productions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWeightedProduction\u001b[49m(non_terminal, rhs, prob))\n\u001b[0;32m     21\u001b[0m weighted_grammar \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mWeightedGrammar(nltk\u001b[38;5;241m.\u001b[39mNonterminal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m), grammar_productions)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Define the input sentence\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'WeightedProduction'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the weighted grammar\n",
    "pcfg_dict = {\n",
    "    'S': [(['NP', 'VP'], 0.5), (['S', 'CC', 'S'], 0.5)],\n",
    "    'NP': [(['Det', 'N'], 1.0)],\n",
    "    'VP': [(['V', 'NP'], 1.0)],\n",
    "    'Det': [(['the'], 0.7), (['a'], 0.3)],\n",
    "    'N': [(['cat'], 0.25), (['dog'], 0.25), (['man'], 0.25), (['woman'], 0.25)],\n",
    "    'V': [(['runs'], 0.4), (['walks'], 0.4), (['jumps'], 0.2)],\n",
    "    'CC': [(['and'], 0.4), (['but'], 0.3), (['or'], 0.3)]\n",
    "}\n",
    "\n",
    "# Convert the PCFG dictionary into an NLTK WeightedGrammar\n",
    "grammar_productions = []\n",
    "for non_terminal, productions in pcfg_dict.items():\n",
    "    for production in productions:\n",
    "        rhs, prob = production\n",
    "        grammar_productions.append(nltk.WeightedProduction(non_terminal, rhs, prob))\n",
    "\n",
    "weighted_grammar = nltk.WeightedGrammar(nltk.Nonterminal('S'), grammar_productions)\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \"the cat runs\"\n",
    "\n",
    "# Create a parser using CYK algorithm\n",
    "parser = nltk.parse.WeightedChartParser(weighted_grammar)\n",
    "\n",
    "# Parse the sentence\n",
    "parses = parser.parse(sentence.split())\n",
    "\n",
    "# Print the parse trees\n",
    "for tree in parses:\n",
    "    print(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b6f8fcf-0f61-4df7-8517-cdff254ec544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ProbabilisticProduction.__init__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m production \u001b[38;5;129;01min\u001b[39;00m productions:\n\u001b[0;32m     18\u001b[0m         rhs, prob \u001b[38;5;241m=\u001b[39m production\n\u001b[1;32m---> 19\u001b[0m         grammar_productions\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProbabilisticProduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNonterminal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_terminal\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprob\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m weighted_grammar \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mWeightedGrammar(nltk\u001b[38;5;241m.\u001b[39mNonterminal(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m), grammar_productions)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Define the input sentence\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: ProbabilisticProduction.__init__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Define the weighted grammar\n",
    "pcfg_dict = {\n",
    "    'S': [(['NP', 'VP'], 0.5), (['S', 'CC', 'S'], 0.5)],\n",
    "    'NP': [(['Det', 'N'], 1.0)],\n",
    "    'VP': [(['V', 'NP'], 1.0)],\n",
    "    'Det': [(['the'], 0.7), (['a'], 0.3)],\n",
    "    'N': [(['cat'], 0.25), (['dog'], 0.25), (['man'], 0.25), (['woman'], 0.25)],\n",
    "    'V': [(['runs'], 0.4), (['walks'], 0.4), (['jumps'], 0.2)],\n",
    "    'CC': [(['and'], 0.4), (['but'], 0.3), (['or'], 0.3)]\n",
    "}\n",
    "\n",
    "# Convert the PCFG dictionary into an NLTK WeightedGrammar\n",
    "grammar_productions = []\n",
    "for non_terminal, productions in pcfg_dict.items():\n",
    "    for production in productions:\n",
    "        rhs, prob = production\n",
    "        grammar_productions.append(nltk.ProbabilisticProduction(nltk.Nonterminal(non_terminal), rhs, prob))\n",
    "\n",
    "weighted_grammar = nltk.WeightedGrammar(nltk.Nonterminal('S'), grammar_productions)\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \"the cat runs\"\n",
    "\n",
    "# Create a parser using CYK algorithm\n",
    "parser = nltk.parse.WeightedChartParser(weighted_grammar)\n",
    "\n",
    "# Parse the sentence\n",
    "parses = parser.parse(sentence.split())\n",
    "\n",
    "# Print the parse trees with probabilities\n",
    "for tree in parses:\n",
    "    print(tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53cec1b4-4deb-4a17-ad29-8e3ec99b6cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S': [(['NP', 'VP'], 1.0)], 'PP': [(['P', 'NP'], 1.0)], 'VP': [(['V', 'NP'], 0.7), (['VP', 'PP'], 0.3)], 'P': [(['with'], 1.0)], 'V': [(['saw'], 1.0)], 'NP': [(['NP', 'PP'], 0.4), (['astronomers'], 0.1), (['ears'], 0.18), (['saw'], 0.04), (['stars'], 0.18), (['telescopes'], 0.1)]}\n",
      "Grammar with 12 productions (start state = S)\n",
      "    S -> NP VP [1.0]\n",
      "    PP -> P NP [1.0]\n",
      "    VP -> V NP [0.7]\n",
      "    VP -> VP PP [0.3]\n",
      "    P -> 'with' [1.0]\n",
      "    V -> 'saw' [1.0]\n",
      "    NP -> NP PP [0.4]\n",
      "    NP -> 'astronomers' [0.1]\n",
      "    NP -> 'ears' [0.18]\n",
      "    NP -> 'saw' [0.04]\n",
      "    NP -> 'stars' [0.18]\n",
      "    NP -> 'telescopes' [0.1]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "grammar = nltk.PCFG.fromstring(\"\"\"\n",
    "    S -> NP VP [1.0]\n",
    "    PP -> P NP [1.0]\n",
    "    VP -> V NP [0.7] \n",
    "    VP -> VP PP [0.3]\n",
    "    P -> 'with' [1.0]\n",
    "    V -> 'saw' [1.0]\n",
    "    NP -> NP PP [0.4]\n",
    "    NP -> 'astronomers' [0.1]\n",
    "    NP -> 'ears' [0.18]\n",
    "    NP -> 'saw' [0.04]\n",
    "    NP -> 'stars' [0.18]\n",
    "    NP -> 'telescopes' [0.1]\n",
    "\n",
    "    \"\"\")\n",
    "\n",
    "# Convert the NLTK PCFG grammar to a Python dictionary\n",
    "pcfg_dict = {}\n",
    "for production in grammar.productions():\n",
    "    lhs = str(production.lhs())\n",
    "    rhs = [str(sym) for sym in production.rhs()]\n",
    "    prob = production.prob()\n",
    "    \n",
    "    if lhs in pcfg_dict:\n",
    "        pcfg_dict[lhs].append((rhs, prob))\n",
    "    else:\n",
    "        pcfg_dict[lhs] = [(rhs, prob)]\n",
    "\n",
    "print(pcfg_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
